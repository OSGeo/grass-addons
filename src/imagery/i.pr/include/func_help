#########################
features_selection.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  and Maria Serafini

  for
  
  Features Selction with SVM
*/

void compute_valoriDJ(svm,features,H_tot,H_tmp,valoriDJ)
     SupportVectorMachine *svm;
     Features *features;
     double **H_tot,**H_tmp,**valoriDJ;
void free_svm(svm)
     SupportVectorMachine *svm;
void e_rfe_lin(svm,features,names,selected,i,rimanenti,fp_fs_w,fp_fs_stats)
     SupportVectorMachine *svm;
     Features *features;
     int *names, *selected;
     int i;
     int *rimanenti;
     FILE *fp_fs_w,*fp_fs_stats;
void e_rfe_gauss(valoriDJ,features,names,selected,i,H_tot,H_tmp,
		 rimanenti,svm_kp,fp_fs_w,fp_fs_stats)
     double *valoriDJ;
     Features *features;
     double **H_tot,**H_tmp;
     int *names, *selected;
     int i;
     int *rimanenti;
     double svm_kp;
     FILE *fp_fs_w,*fp_fs_stats;
void one_rfe_lin(svm,names,selected,fp_fs_w)
     SupportVectorMachine *svm;
     int *names, *selected;
     FILE *fp_fs_w;
void one_rfe_gauss(valoriDJ,names,selected,n,fp_fs_w)
     double *valoriDJ;
     int *names, *selected;
     int n;
     FILE *fp_fs_w;
void rfe_lin(svm,features,names,selected,i,fp_fs_w)
     SupportVectorMachine *svm;
     Features *features;
     int *names, *selected;
     int i;
     FILE *fp_fs_w;
void rfe_gauss(valoriDJ,features,names,selected,i,H_tot,H_tmp,svm_kp,fp_fs_w)
     Features *features;
     double *valoriDJ;
     int *names, *selected;
     double **H_tot,**H_tmp;
     int i;
     double svm_kp;
     FILE *fp_fs_w;
void write_matrix(outfile,matrix,r,c)
     char *outfile;
     double **matrix;
     int r,c;
void compute_H(matrix,XX,y,ndati,nfeat,sigma)
     double **matrix,**XX;
     int *y;
     double sigma;
     int ndati,nfeat;
void compute_H_perdiff(Hvecchia,Hnuova,XX,ndati,sigma,featdaelim)
     double **Hvecchia,**Hnuova,**XX;
     double sigma;
     int ndati,featdaelim;

     // featdaelim e' la variabile numerata come numera C (0...nfeat-1)
void traslo(x,n)
     double *x;
     int n;

#########################
soft_margin_boosting.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  Soft Boosting implementation (quadratic programming)
*/

void maximize(alpha,N,beta,T,M)
     double *alpha,*beta,**M;
     int N,T;

#########################
write_matrix.c
#########################

void write_matrix(outfile,matrix,r,c)
     char *outfile;
     double **matrix;
     int r,c;

#########################
entropy.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  Entropy management
*/

double Entropy(data,n,zero)
     double *data;
     int n;
     double zero;
double Clog(x,zero)
     double x;
     double zero;
void histo(data,n,h,nbin)
     double *data, *h;
     int n,nbin;
void histo1(data,n,h,nbin)
     double *data;
     int n,nbin;
     int *h;


#########################
min_quadratic.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  quadratic programming
*/

void mqc(M,m,n,H,h,mH,K,k,mK,eps,x,minvalue)
     double **M,*m;
     double **H,*h;
     double **K,*k;
     int n,mH,mK;
     double eps;
     double *x;
     double *minvalue;
{
  int i,j,l;

  double **invM;
  double **HM,**HMH,*tnH,**HMK,**KM,**KMK,*tnK,**tH,**tK;  
  double mMm;
  double gap;
  double *alpha,*beta;
  double L,f;
  double tmpalpha,tmpbeta,tmpL,tmpf;

  /*alloc memory*/
  invM=(double**)calloc(n,sizeof(double*));
  for(i=0;i<n;i++)
    invM[i]=(double*)calloc(n,sizeof(double));

  if(mH>0){
    HM=(double**)calloc(mH,sizeof(double*));
    for(i=0;i<mH;i++)
      HM[i]=(double*)calloc(n,sizeof(double));
    
    HMH=(double**)calloc(mH,sizeof(double*));
    for(i=0;i<mH;i++)
      HMH[i]=(double*)calloc(mH,sizeof(double));
    
    tnH=(double*)calloc(mH,sizeof(double));
    
    tH=(double**)calloc(n,sizeof(double*));
    for(i=0;i<n;i++)
      tH[i]=(double*)calloc(mH,sizeof(double));
    
    for(i=0;i<mH;i++)
      for(j=0;j<n;j++)
	tH[j][i]=H[i][j];
  }

  if(mH>0 && mK>0){
    HMK=(double**)calloc(mH,sizeof(double*));
    for(i=0;i<mH;i++)
      HMK[i]=(double*)calloc(mK,sizeof(double));
  }

  if(mK>0){
    KM=(double**)calloc(mK,sizeof(double*));
    for(i=0;i<mK;i++)
      KM[i]=(double*)calloc(n,sizeof(double));
    
    KMK=(double**)calloc(mK,sizeof(double*));
    for(i=0;i<mK;i++)
      KMK[i]=(double*)calloc(mK,sizeof(double));
    
    tnK=(double*)calloc(mK,sizeof(double));

    tK=(double**)calloc(n,sizeof(double*));
    for(i=0;i<n;i++)
      tK[i]=(double*)calloc(mK,sizeof(double));
    
    for(i=0;i<mK;i++)
      for(j=0;j<n;j++)
	tK[j][i]=K[i][j];
  }

  /*compute inverse of M*/
  inverse_of_double_matrix(M,invM,n);

  /*compute matrices products*/
  if(mH>0){
    product_double_matrix_double_matrix(H,invM,mH,n,n,HM);
    product_double_matrix_double_matrix(HM,tH,mH,n,mH,HMH);
    product_double_matrix_double_vector(HM,m,mH,n,tnH);
    for(i=0;i<mH;i++)
      tnH[i] += 2.*h[i];
  }

  if(mH>0 && mK>0)
    product_double_matrix_double_matrix(HM,tK,mH,n,mK,HMK);

  if(mK>0){  
    product_double_matrix_double_matrix(K,invM,mK,n,n,KM);
    product_double_matrix_double_matrix(KM,tK,mK,n,mK,KMK);
    product_double_matrix_double_vector(KM,m,mK,n,tnK);
    for(i=0;i<mK;i++)
      tnK[i] += 2.*k[i];
  }
  
 
  mMm=0.0;
  for(i=0;i<n;i++)
    for(j=0;j<n;j++)
      mMm+=m[i]*m[j]*invM[i][j];
  mMm *= -.5;

  if(mH>0)
    alpha=(double*)calloc(mH,sizeof(double));
  if(mK>0)
    beta=(double*)calloc(mK,sizeof(double));

  gap=eps+1;
  /*gradient ascendent on the dual Lagrangian*/
  while(gap>eps){
    if(mH>0 && mK>0){
      for(l=0;l<mH;l++){
	
	tmpalpha=.0;
	for(i=0;i<mH;i++)
	  if(alpha[i]>0)
	    tmpalpha += HMH[i][l]*alpha[i];
	
	tmpalpha += tnH[l];
	
	
	for(i=0;i<mK;i++)
	  tmpalpha += HMK[l][i]*beta[i];
	
	alpha[l] -= tmpalpha/HMH[l][l];
	
	if(alpha[l] < .0)
	  alpha[l] = .0;
      }

      for(l=0;l<mK;l++){
	tmpbeta=.0;
	for(i=0;i<mK;i++)
	  tmpbeta += KMK[i][l]*beta[i];
	
	tmpbeta += tnK[l];
	
	
	for(i=0;i<mH;i++)
	  if(alpha[i]>0)
	    tmpbeta += HMK[i][l]*alpha[i];
	
	beta[l] -= tmpbeta/KMK[l][l];

      }
    }else if(mH>0 && mK==0){
      for(l=0;l<mH;l++){
	
	tmpalpha=.0;
	for(i=0;i<mH;i++)
	  if(alpha[i]>0)
	    tmpalpha += HMH[i][l]*alpha[i];
	
	tmpalpha += tnH[l];
	
	alpha[l] -= tmpalpha/HMH[l][l];
	if(alpha[l] < .0)
	  alpha[l] = .0;
      }
    }else if(mH==0 && mK>0){
      for(l=0;l<mK;l++){
	tmpbeta=.0;
	for(i=0;i<mK;i++)
	  tmpbeta += KMK[i][l]*beta[i];
	
	tmpbeta += tnK[l];
	
	beta[l] -= tmpbeta/KMK[l][l];

      }
    }

    /*value of the dual Lagrangian*/
    L=mMm;

    tmpL=.0;
    for(i=0;i<mH;i++)
      if(alpha[i]>0)
	for(j=0;j<mH;j++)
	  if(alpha[j]>0)
	    tmpL += alpha[i]*alpha[j]*HMH[i][j];
    L -= .5*tmpL;

    tmpL=.0;
    for(i=0;i<mH;i++)
      if(alpha[i]>0)
	tmpL += alpha[i]*tnH[i];
    L -= tmpL;

    tmpL=.0;
    for(i=0;i<mK;i++)
      for(j=0;j<mK;j++)
	tmpL += beta[i]*beta[j]*KMK[i][j];
    L -= .5*tmpL;
    
    tmpL=.0;
    for(i=0;i<mK;i++)
      tmpL += beta[i]*tnK[i];
    L -= tmpL;
   
    tmpL=.0;
    for(i=0;i<mH;i++)
      if(alpha[i]>0)
	for(j=0;j<mK;j++)
	  tmpL += alpha[i]*beta[j]*HMK[i][j];
    L -= tmpL;

    L *= .5;
    
    /*value of the objective function*/
    f=mMm-L;

    tmpf=.0;
    for(i=0;i<mH;i++)
      if(alpha[i]>0)
	tmpf += alpha[i]*tnH[i];
    f -= .5*tmpf;

    tmpf=.0;
    for(i=0;i<mK;i++)
      tmpf += beta[i]*tnK[i];
    f -= .5*tmpf;
    
    /* gap between dual Lagrangian and objective function (stopping criteria)*/
    gap=fabs((f-L)/(f+1.));
    printf("%f\n",gap);

  }

  /*minimum*/

  for(l=0;l<n;l++){
    x[l] = .0;
    
    for(i=0;i<mH;i++)
      if(alpha[i]>0)
	x[l] +=HM[i][l]*alpha[i];

    for(i=0;i<mK;i++)
      x[l] +=KM[i][l]*beta[i];
    
    for(i=0;i<n;i++)
      x[l] +=invM[l][i]*m[i];

    x[l] *= -.5;
  }
  for(i=0;i<mH;i++)
    printf("a[%d]=%f\n",i,alpha[i]);
  for(i=0;i<mK;i++)
    printf("b[%d]=%f\n",i,beta[i]);

  /*value of the function*/
  *minvalue=f;
  

  /*free memory*/
  for(i=0;i<n;i++)
    free(invM[i]);
  free(invM);

  if(mH>0){
    free(alpha);
    free(tnH);
    for(i=0;i<mH;i++){
      free(HM[i]);
      free(HMH[i]);
    }
    free(HM);
    free(HMH);
    for(i=0;i<n;i++)
      free(tH[i]);
    free(tH);
  }

  if(mK>0){
    free(beta);
    free(tnK);
    for(i=0;i<mK;i++){
      free(KM[i]);
      free(KMK[i]);
    }
    free(KM);
    free(KMK);
    for(i=0;i<n;i++)
      free(tK[i]);
    free(tK);
  }

  if(mK>0 && mH>0){
    for(i=0;i<mH;i++)
      free(HMK[i]);
    free(HMK);
  }
    
}


#########################
blob.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  Blob and BlobSites structure management
*/

void extract_sites_from_blob(blobs,npoints,nblobs,cellhd,sites,matrix)
     /*extract geographical coordinates of the blob centers
       and store results in a BlobSites structure, containing the minimum 
       value of the blob too (computation based on matrix)*/
     Blob *blobs;
     int npoints,nblobs;
     struct Cell_head *cellhd;
     BlobSites *sites;
     double **matrix;
void find_blob(matrix,r,c,blobs,npoints,nblobs,tm,tM)
     /*find blobs within a matrix and add to structure blob. A blob is
       a set of contiguous cells of a matrix, all of them with value <=
       tM and >= tm.  npoints is just a counter of cells belonging to the blob.
       nblobs is the total number of blobs.*/
     double **matrix;
     int r,c;
     Blob **blobs;
     double tm,tM;
     int *nblobs;
     int *npoints;

#########################
test.c
#########################

/*
  The following routines are borrowed from "Numerical Recipes in C"
  and rearranged by Stefano Merler

  for 
  
  statistical test computation

  Supported functions for:
  - KS test the normal distribution of data
  - KS test for equality of 2 distribution
  - t-test for mean
*/

void ksone_normal(data,n,p1,p2,d,prob)
     /*
       KS test for normal distribution. data is the array of data 
       of length n. p1 and p2 mean and sd of the normal distribution
       tested. On output d is the value of the test and prob
       the p-value
     */
     double *data,*d,*prob;
     int n;
     double p1,p2;
     
void kstwo(data1,n1,data2,n2,d,prob)
     /*
       KS test for testing 2 distribution. data1 is the first 
       array of data of length n1. data2 is the second array
       of data of length n2. On output d is the value of the
       test and prob the p-value
     */
     double *data1, *data2, *d, *prob;
     int n1,n2;
double normal_distribution(x,mu,sigma)
     /*
       normal distribution with mean mu and
       standard deviation sigma computed at point x

       1/(sigma*sqrt(PIG) exp(-(x-mu)^2/2sigma^2)
     */
     double x,mu,sigma;
double cumulative_normal_distribution(mu,sigma,x)
     /*
       cumulative probability of the normal
       distribution with mean mu and
       standard deviation sigma, i.e.
       integral from -Inf to x
  
     */
     double mu,sigma,x;
void tutest(data1,n1,data2,n2,t,prob)
     /*
      */
     double *data1, *data2, *t, *prob;
     int n1,n2;

#########################
read_models.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  loading different model types
*/

int read_model(file,features,nn,gm,tree,svm,btree,bsvm)
     /*read a model from file and fill the structure according to the
       model type. Moreover load the features*/
     char *file;
     NearestNeighbor *nn;
     GaussianMixture *gm;
     Tree  *tree;
     SupportVectorMachine *svm;
     BTree *btree;
     BSupportVectorMachine *bsvm;
     Features *features;

#########################
nn.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  structure NearestNeighbor management
*/

void compute_nn(nn,nsamples,nvar,data,data_class)
     /*
       Compute nn model, given a matrix of examples data of dimension
       nsamples x nvar. Classes of each example are contained in data_class.
     */
     NearestNeighbor *nn;
     int nsamples,nvar;
     double **data;
     int *data_class;
void write_nn(file,nn,features)
     /*
       write nn structure to a file 
     */
     char *file;
     NearestNeighbor *nn;
     Features *features;
int predict_nn_multiclass(nn,x,k,nclasses,classes)
     /* 
	multiclass problems: given a nn model, return the predicted class of a test point x 
	using k-nearest neighbor for the prediction. the array classes (of length nclasses)
	shall contain all the possible classes to be predicted
     */
     NearestNeighbor *nn;	
     double *x;
     int k;
     int *classes;
     int nclasses;
double predict_nn_2class(nn,x,k,nclasses,classes)
     /* 
	2 class problems: given a nn model, return the majority of the class (with sign) 
	of a test point x using k-nearest neighbor for the prediction. 
	the array classes (of length nclasses)	shall contain all the possible 
	classes to be predicted
     */
     NearestNeighbor *nn;	
     double *x;
     int k;
     int *classes;
     int nclasses;
void test_nn(nn,features,k,file)
     /*
       test nn model on a set of data (features) using k-nearest neighbor 
       and write the results into a file. To standard output accuracy 
       and error on each class
     */
     NearestNeighbor *nn;
     Features *features;
     char *file;
     int k;

#########################
svm.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  structures SupportVectorMachine adn  BSupportVectorMachine management
*/


void compute_svm(svm,n,d,x,y,svm_kernel,svm_kp,svm_C,svm_tol,svm_eps,
		 svm_maxloops,svm_W)
     SupportVectorMachine *svm;
     int n,d;
     double **x;
     int *y;
     int svm_kernel;
     double svm_kp,svm_C,svm_tol,svm_eps;
     int svm_maxloops;
     double *svm_W;
void estimate_cv_error(SVM)
     SupportVectorMachine *SVM;
void write_svm(file,svm,features)
     /*
       write svm structure to a file 
     */
     SupportVectorMachine *svm;
     char *file;
     Features *features;
void test_svm(svm,features,file)
     /*
       test svm model on a set of data (features) and write the results
       into a file. To standard output accuracy and error on each class
     */
     SupportVectorMachine *svm;
     Features *features;
     char *file;
double predict_svm(svm,x)
     /* 
	given a svm model, return the predicted margin of a test point x
     */
     SupportVectorMachine *svm;
     double *x;
void compute_svm_bagging(bsvm,bagging,nsamples,nvar,data,data_class,
			 svm_kernel,kp,C,tol,eps,maxloops,svm_W)
     BSupportVectorMachine *bsvm;
     int bagging;
     int nsamples,nvar;
     double **data;
     int *data_class;
     int svm_kernel;
     double kp;
     double C;
     double tol;
     double eps;
     int maxloops;
     double *svm_W;
void write_bagging_boosting_svm(file,bsvm,features)
     /*
       write a bagging or boosting svm to a file
     */
     char *file;
     BSupportVectorMachine *bsvm;
     Features *features;
void compute_svm_boosting(bsvm,boosting,w,nsamples,nvar,data,data_class,
			  nclasses,classes, svm_kernel,kp,C,tol,svm_eps,
			  maxloops,svm_W,weights_boosting)

     BSupportVectorMachine *bsvm;
     int boosting;
     double w;
     int nsamples,nvar;
     double **data;
     int *data_class;
     int *classes;
     int nclasses;
     int svm_kernel;
     double kp;
     double C;
     double svm_eps;
     double tol;
     int maxloops;
     double *svm_W;
     int weights_boosting;

double predict_bsvm(bsvm,x)
     /* 
	given a bsvm model, return the predicted margin of a test point x
     */
     BSupportVectorMachine *bsvm;	
     double *x;
void test_bsvm(bsvm,features,file)
     /*
       test bagging or boosting svm model on a set of data (features) 
       and write the results into a file. To standard output accuracy 
       and error on each class
     */
     BSupportVectorMachine *bsvm;
     Features *features;
     char *file;
double dot_product(x,y,n)
     double *x,*y;
     int n;


#########################
features.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  structure Feature management
*/
void compute_features(features)
     /*
       given a training structure in input, fill the features structure
       according to specification lyke
       features->f_mean
       features->f_variance
       features->f_pca
       features->f_texture (not yet implemented)
     */
     Features *features;
  space_for_each_layer=(int *)G_calloc(features->training.nlayers,
				       sizeof(int));
  features->examples_dim = 0;
      features->p_classes=(int *)realloc(features->p_classes,
					 features->nclasses * sizeof(int));
      features->p_classes[features->nclasses-1] = features->class[i];
    }
  }

  /*space for pca*/
void write_features(file,features)
     /*
       write the features into a file
     */
     char *file;
     Features *features;
void standardize_features(features)
     /*
       standardize fetures accordining to the fetures.f_standardize array
     */
     Features *features;
void write_header_features(fp,features)
     /*
       write the header features into the pointed  file
     */
     FILE *fp;
     Features *features;
void read_features(file,features,npc)
     /*
       read the features from a file. If pc structure is contained
       within features, only load the first npc component. If npc < 0
       all the pc will be loaded.
     */
     char *file;
     Features *features;
     int npc;
      features->value[i]=(double *)G_calloc(features->examples_dim,
					    sizeof(double));
    }
    features->class=(int *)G_calloc(features->nexamples,sizeof(int));
    
    line=GetLine(fp);
    line=GetLine(fp);
void read_header_features(fp,features)
     /*
       read the hearder features from the file pointed
     */
     FILE *fp;
     Features *features;

#########################
gm.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  structure GaussianMixture management
*/

void compute_gm(gm,nsamples,nvar,data,data_class,nclasses,classes)
     /*
       Compute gm model, given a matrix of examples data of dimension
       nsamples x nvar. Classes of each example are contained in data_class.
       the array classes (of length nclasses) shall contain all the possible
       classes of the array data_class
     */
     GaussianMixture *gm;
     int nsamples,nvar;
     double **data;
     int *data_class;
     int *classes;
     int nclasses;
void write_gm(file,gm,features)
     /*
       write gm structure to a file 
     */
     char *file;
     GaussianMixture *gm;
     Features *features;
void test_gm(gm,features,file)
     /*
       test gm model on a set of data (features) and write the results
       into a file. To standard output accuracy and error on each class
     */
     GaussianMixture *gm;
     Features *features;
     char *file;
void compute_test_gm(gm)
     /*
       compute inverse and determinant of each covariance matrix of a gm model
     */
     GaussianMixture *gm;
int predict_gm_multiclass(gm,x)
     /* 
	multiclass problems: given a gm model, return the predicted class 
	of a test point x
     */
     GaussianMixture *gm;
     double *x;
double predict_gm_2class(gm,x)
     /* 
	2 class problems: given a gm model , return the posterior of class (with sign) for 
	a test point x
     */
     GaussianMixture *gm;
     double *x;

#########################
training.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  structure Training management
*/

void inizialize_training(training)
     /* 
	alloc memory for training (see global.h for details)
     */
     Training *training;
void read_training(file,training)
     /*
       read training structure from a file. Supported formats
       GRASS_data:list of labelled raster maps
       TABLE_data:list of labelled vecors
     */
     char *file;
     Training *training;
      training->data[training->nexamples]=(double *)G_calloc(training->cols,
							     sizeof(double));

#########################
tree.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  structure Tree and BTree management
*/

void  compute_tree(tree,nsamples,nvar,data,data_class,nclasses,
		   classes,stamps,minsize,costs)
     /*
       receives in input training data of dimensions nsamples x nvar, 
       with class labels data_class, the possible classes (of length nclasses)
       and computes a tree model; optionally, the user can build stamps 
       and decide the minimal number of cases within a node as 
       stopping criteria. 
     */
     Tree *tree;
     int nsamples,nvar;
     double **data;
     int *data_class;
     int *classes;
     int nclasses;
     int stamps;
     int minsize;
     double *costs;
void write_tree(file,tree,features)
     /*
       write a tree model to a file
     */
     char *file;
     Tree *tree;
     Features *features;
void compute_tree_boosting(btree,boosting,w,nsamples,nvar,data,data_class,
			   nclasses,classes, stamps,minsize,weights_boosting,
			   costs)
     /*
       receives in input training data of dimensions nsamples x nvar, 
       with class labels data_class, the possible classes (of length nclasses)
       and computes a boosting tree model (number of models = boosting) using w
       as parameter for the cost sensitive procedure;
       optionally, the user can build stamps and decide the 
       minimal number of cases within a node as stopping criteria. 
     */
     BTree *btree;
     int boosting;
     double w;
     int nsamples,nvar;
     double **data;
     int *data_class;
     int *classes;
     int nclasses;
     int stamps;
     int minsize;
     int weights_boosting;
     double *costs;
void compute_tree_bagging(btree,bagging,nsamples,nvar,data,data_class,
			 nclasses,classes,stamps,minsize,costs)
     /*
       receives in input training data of dimensions nsamples x nvar, 
       with class labels data_class, the possible classes (of length nclasses)
       and computes a bagging tree model (number of models = bagging);
       optionally, the user can build stamps and decide the 
       minimal number of cases within a node as stopping criteria. 
     */
     BTree *btree;
     int bagging;
     int nsamples,nvar;
     double **data;
     int *data_class;
     int *classes;
     int nclasses;
     int stamps;
     int minsize;
     double *costs;
void write_bagging_boosting_tree(file,btree,features)
     /*
       write a bagging or boosting tree model to a file
     */
     char *file;
     BTree *btree;
     Features *features;
int predict_tree_multiclass(tree,x)
     /* 
	multiclass problems: given a tree model, return the predicted class 
	of a test point x
     */
     Tree *tree;	
     double *x;
double predict_tree_2class(tree,x)
     /* 
	2 class problems: given a tree model, return the proportion of data
	in the terminal node (with sign) of a test point x
     */
     Tree *tree;	
     double *x;
void test_tree(tree,features,file)
     /*
       test a tree model on a set of data (features) and write the results
       into a file. To standard output accuracy and error on each class
     */
     Tree *tree;
     Features *features;
     char *file;
double predict_btree_2class(btree,x)
     /* 
	for 2 classes problems: given a btree model, return the predicted
	margin of a test point x
     */
     BTree *btree;	
     double *x;
int predict_btree_multiclass(btree,x,nclasses,classes)
     /* 
	for multiclasses problems: given a btree model, return the predicted
	class of a test point x
     */
     BTree *btree;	
     double *x;
     int *classes;
     int nclasses;
void test_btree(btree,features,file)
     /*
       test a btree model on a set of data 
       (features) and write the results into a file. To standard output
       accuracy and error on each class
     */
     BTree *btree;
     Features *features;
     char *file;

#########################
matrix.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  management of matrices and arrays

  Supported function for 
  - product matrix matrix or vector matrix
  - transpose matrix
  - conversion of matrix to array
  - extraction of portion of matrix
*/

void product_double_matrix_double_matrix(x,y,r,cr,c,out)
     /*
       product of matrices x * y, 
       r = rows of x 
       cr= cols of x = rows of y
       c = cols of y
       out is the r x c matrix. 
     */
     double **x, **y, **out;
     int r,cr,c;
void product_double_matrix_double_vector(x,y,r,cr,out)
     /*
       vector x matrix y * x, 
       r = rows of x 
       cr= cols of x = elements of y
       out is the output vector (r elements) . Memory for out is not stored.
     */
     double **x, *y, *out;
     int r,cr;
void product_double_vector_double_matrix(x,y,rr,c,out)
     /*
       vector x matrix y * x, 
       rr = rows of x = elements of y 
       c= cols of x 
       out is the output vector (c elements) . Memory for out is not stored.
     */
     double **x, *y, *out;
     int rr,c;
void transpose_double_matrix(x,n)
     /*
       transpose, and overwrite, the input matrix x 
       of dimension n x n
     */
     double **x;
     int  n;
void double_matrix_to_vector(mat,rows,cols,vect)
     /*
       transform matrix mat of dimension rows x cols in vector
       vect of length rows x cols.
       matrix is scanned by row
     */
     double **mat;
     int rows, cols;
     double *vect;
void extract_portion_of_double_matrix(r,c,br,bc,mat,wind)
     /*
       extract a squared portion of a matrix mat
       given a the indeces of the center [r,c] 
       and the semilength of the borders [br,bc]
       Output to array wind
     */
     int r, c, br, bc;
     double **mat, **wind;
void transpose_double_matrix_rectangular(x,n,m,trans)
     /*
       transpose the input matrix x  of dimension n x m
       output to pointer to matrix trans
     */
     double **x,***trans;
     int  n,m;

#########################
pca.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  structure Pca management
*/


void inizialize_pca(pca,dim)
     /* 
	alloc memory for Pca structure pca of dimension dim
     */
     Pca *pca;
     int dim;
void write_pca(fp,pca)
     /* write a pca structure into the file pointed*/
     FILE *fp;
     Pca *pca;
void read_pca(fp,pca)
     /* raed a pca structure from the file pointed*/
     FILE *fp;
     Pca *pca;

#########################
random.c
#########################

/*
  The following routines are borrowed from "Numerical Recipes in C"
  
  for 
  
  extraction of samples from normal and uniform distributions
*/

double ran1(idum)
     /*
       return a double from a uniform distributio over [0,1].
       Idum inizialize the procedure
     */
     int *idum;
double gasdev(idum)
     /*
       return a double from a normal distribution (m=0, v=1).
       Idum inizialize the procedure
     */
     int *idum;

#########################
bootstrap.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  bootstrap, probabily based, samples estraction
*/

void Bootsamples(n,prob,random_labels)
     /*
       given an array of probabilities of length n, extract a bootstrap sample
       of n elements according to the vector of probabilities
     */
     int n;
     double *prob;
     int *random_labels;
     
void Bootsamples_rseed(n,prob,random_labels,idum)
     /*
       given an array of probabilities of length n, extract a bootstrap sample
       of n elements according to the vector of probabilities
     */
     int n;
     double *prob;
     int *random_labels;
     int *idum;
     

#########################
dist.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  Distance between arrays computation
*/

double squared_distance(x,y,n)
     /*
       squared euclidean distance between vectors x and y of length n
     */
     double *x;
     double *y;
     int n;
double euclidean_distance(x,y,n)
     /*
       euclidean distance between vectors x and y of length n
     */
     double *x, *y;
     int n;
double scalar_product(x,y,n)
     /*
       scalar product between vector x and y of length n
     */
     double *x,*y;
     int n;
double euclidean_norm(x,n)
     /*
       euclidean norm of a  vector x of length n
     */
     double *x;
     int n;

#########################
open.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  open new raster maps
*/

int open_new_CELL(name)
     /* 
	open a new raster map of name name in CELL format
     */
     char *name;
int open_new_DCELL(name)
     /* 
	open a new raster map of name name in DELL format
     */
     char *name;

#########################
percent.c
#########################

/*
  The following routines are written and tested by Stefano Merler

  for
  
  status of a loop computation
*/

void percent (n,d,s)
     /*
       compute percentage (and print to stderr)
       of work done within a loop. 
       n actual number, d total number, s step
     */
     int n,d,s;
     

#########################
getline.c
#########################

/*
  The following routine is written and tested by Stefano Merler

  for
  
  getting a line from a buffered stream
*/

char *GetLine(fp)
     /*
       get a line from a buffered stream (pointed from fp)
     */
     FILE    *fp;

#########################
sort.c
#########################

/*
  The following routines is borrowed from "Numerical Recipes in C"
  
  for

  sortinf of an array 
*/

void shell(n,arr)
     /*  
	 sort and rearranges an array arr of length n 
	 into ascending order
     */
     double *arr;
     int n;
void indexx_1(n,arrin,indx)
     /*
       sort array arrin of length n into ascending order,
       without modify it. The order of the sording will be
       contained into the indx array
     */
     int n, indx[];	
     double arrin[];	

#########################
integration.c
#########################

/*
  Same of the following routines are borrowed from "Numerical Recipes in C"
  other are written and tested by Stefano Merler

  for
  
  integration of function using the trapezoidal rule

  Supported function for 
  - non-parametric functions
  - functions depending from 1 parameter
  - functions depending from 2 parameters
*/


double trapzd(func,a,b,n)
     /* 
	trapezoidal rule for func=func(x) on interval [a,b]
	n = steps number
     */
     double a,b;
     double (*func)();
     int n;
double trapzd1(func,p1,a,b,n)
     /* 
	trapezoidal rule for func=func(x; p1) on interval [a,b]
	p1 free parameter
	n = steps number
     */
     double a,b;
     double p1;
     double (*func)();
     int n;
double trapzd2(func,p1,p2,a,b,n)
     /* 
	trapezoidal rule for func=func(x; p1,p2) on interval [a,b]
	p1 and p2 free parameters
	n = steps number
     */
     double a,b;
     double p1,p2;
     double (*func)();
     int n;
double qtrap(func,a,b)
     /* 
	trapezoidal rule for func=func(x) with stopping rule
     */
     double a,b;
     double (*func)();
double qtrap1(func,p1,a,b)
     /* 
	trapezoidal rule for func=func(x) on interval [a,b]
	with internal stopping rule
	p1  free parameter
     */
     double a,b;
     double p1;
     double (*func)();
double qtrap2(func,p1,p2,a,b)
     /* 
	trapezoidal rule for func=func(x) on interval [a,b]
	with internal stopping rule
	p1 and p2 free parameters
     */
     double a,b;
     double p1,p2;
     double (*func)();

#########################
eigen.c
#########################

/*
  Same of the following routines are borrowed from "Numerical Recipes in C"
  other are written and tested by Stefano Merler

  for

  Eigenvalues and eigenvectors of simmetric matrices compution
  and management
*/

void tred2(a,n,d,e)
     /*
       Houserholder method for reduction of simmetric n x n matrix a to 
       tridiagonal form: on output a contains the ortogonal transformation
       matrix, d contains the diagonal elements, and e the off-diagonal.
      */
     double **a,d[],e[];
     int n;
int tqli(d,e,n,z)
     /*
       QL algorithm: compute eigenvalues and eigenvectors 
       of simmetric tridiagonal matrix. On input, d diagonal 
       and e off-diagonal elements of the matrix (usually the 
       output of tred2), z the matrix output of tred2.
       On output d eigenvalues, z eigenvectors.
      */
     double d[],e[],**z;
     int n;
void eigen_of_double_matrix(M, Vectors, lambda, n) 
     /* 
	Computes eigenvalues (and eigen vectors if desired) for	
	symmetric matrix M of dimension n x n.
 	Vectors and lambda contain the (obvious) output.
     */
     double 	**M;	
     double  **Vectors; 
     double  *lambda;   
     int	n;	
void eigsrt(d,z,bands)
     /* sort eigenvalues d in descending order, and rearranges 
	eigenvectors z correspondingly. bands contains the number 
	of eigenvalues = rows of z = cols of z
     */
     double *d,**z;
     long   bands;

#########################
stats.c
#########################

/*
  The following routing are written and tested by Stefano Merler

  for 

  statistical description of data

  Supported function for:
  - mean computation
  - standard deviation and variance computation
  - autocovariance computation
  - covariance matrix computation
  -min-max of an array
*/

double mean_of_double_array(x,n)
     /* 
	compute the mean of an array x of lenth n
     */
     double *x;
     int n;
double var_of_double_array(x,n)
     /* 
	compute the var of an array x of length n
     */
     double *x;
     int n;
double sd_of_double_array(x,n)
     /* 
	compute the sd of an array x of length n
     */
     double *x;
     int n;
double var_of_double_array_given_mean(x,n,mean)
     /* 
	compute the var of an array x of length n
	without computation of the mean mean, 
	given in input
     */
     double *x;
     double mean;
     int n;
double sd_of_double_array_given_mean(x,n,mean)
     /* 
	compute the sd of an array x of length n
	without computation of the mean, 
	given in input
     */
     double *x;
     double mean;
     int n;
void mean_and_var_of_double_matrix_by_row(x,n,m,mean,var)
     /* 
	each row of the input matrix x (dimension n x m)
	is considered an independent array of data. 
	The function compute mean and var of each row, 	
	stored within the array mean and var. 
     */
     double **x;
     int n;
     int m;
     double *mean;
     double *var;
void mean_and_sd_of_double_matrix_by_row(x,n,m,mean,sd)
     /* 
	each row of the input matrix x (dimension n x m)
	is considered an independent array of data. 
	The function compute mean and sd of each row, 	
	stored within the array mean and sd. 
     */
     double **x;
     int n;
     int m;
     double *mean;
     double *sd;
void mean_and_var_of_double_matrix_by_col(x,n,m,mean,var)
     /* 
	each col of the input matrix x (dimension n x m)
	is considered an independent array of data. 
	The function compute mean and var of each col, 	
	stored within the array mean and sd. 
     */
     double **x;
     int n;
     int m;
     double *mean;
     double *var;
void mean_and_sd_of_double_matrix_by_col(x,n,m,mean,sd)
     /* 
	each col of the input matrix x (dimension n x m)
	is considered an independent array of data. 
	The function compute mean and sd of each col, 	
	stored within the array mean and sd. 
     */
     double **x;
     int n;
     int m;
     double *mean;
     double *sd;
double auto_covariance_of_2_double_array(x,y,n)
     /* 
	compute the auto covariance of 2 array x and y of length n
     */
     double *x;
     double *y;
     int n;
void covariance_of_double_matrix(x,n,m,cov)
     /*
       compute covariance matrix of a matrix x of dimension n x m.
       Output to matrix cov.
     */
     double **x;
     double **cov;
     int n,m;
double entropy(p,n)
     /*
       compute and return entropy of an array p (his components to be intended
       as proportions) of length n
     */
     double *p;	
     int n;
double gaussian_kernel(x,y,n,kp)
     /*
       compute e return gaussian kernel exp(-sqrt(||x-y||)/kp),
       x and y array of length n
     */
     double *x,*y;
     int n;
     double kp;
double squared_gaussian_kernel(x,y,n,kp)
     /*
       compute e return gaussian kernel exp(-||x-y||/kp),
       x and y array of length n
     */
     double *x,*y;
     int n;
     double kp;
double min(x,n)
     double *x;
     int n;
double max(x,n)
     double *x;
     int n;

#########################
lu.c
#########################

/*
  Same of the following routines are borrowed from "Numerical Recipes in C"
  other are written and tested by Stefano Merler

  for
  
  LU matrix decomposition, linear equation solution (Ax=b), inversion
  of matrices and deteminant computation
*/

void ludcmp(a,n,indx,d)
     /*
       LU decomposition of n x n matrix a.
     */
     int n,*indx;
     double **a,*d;
void lubksb(a,n,indx,b)
     /* 
	Solve linear equation Ax=B
	a has to be a LU decomposed n x n matrix, and indx 
	is usually the output of ludcmp.
	On output, b contains the solution
     */
     double **a,b[];
     int n,*indx;
void inverse_of_double_matrix(A,inv_A,n)
     /* 
	Inverse of a matrix A of dimension n x n.
	Output stored in inv_A
     */	
     double **A,**inv_A;
     int n;
double determinant_of_double_matrix(A,n)
     /* 
	determinant of a double matrix A of dimension n x n
     */
     double **A;
     int n;
