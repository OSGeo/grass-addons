#include <grass/gis.h>
#include "global.h"
#include <stdlib.h>
#include <string.h>
#include <math.h>

void write_matrix();

int main(int argc, char **argv)
{
    struct Option *opt1;
    struct Option *opt2;
    struct Option *opt3;
    struct Flag *flag_c;
    struct Flag *flag_b;

    Features features;
    Features *tr_features;
    Features *ts_features;

    char tmpbuf[500];
    int n_sets;
    int i, j, k;
    char fileout[500], filelab[500];
    FILE *flab;
    double *prob;
    int *random_labels, *non_extracted;
    int n_non_extracted;
    int n_extracted;
    int extracted;
    int indx;
    int idum;
    double probok;
    int seed;

    char gisrc[500];

    if (getenv("GISBASE") == NULL)
	setenv("GISBASE",
	       "/mpa_sw/ssi/BIO/software/GRASS5.0.0/grass5bin_cvs/grass5", 1);
    if (getenv("GISRC") == NULL) {
	sprintf(gisrc, "/ssi0/ssi/%s/.grassrc5", getenv("LOGNAME"));
	setenv("GISRC", gisrc, 1);
    }

    /* Initialize the GIS calls */
    G_gisinit(argv[0]);

    /* set up command line */
    opt1 = G_define_option();
    opt1->key = "features";
    opt1->type = TYPE_STRING;
    opt1->required = YES;
    opt1->description =
	"Input file containing the features (output of i.pr_features).";

    opt2 = G_define_option();
    opt2->key = "n_sets";
    opt2->type = TYPE_INTEGER;
    opt2->required = YES;
    opt2->description =
	"Number of subsets (>=1). If you set n_sets=1 and select  cross-validation,\n\t\tleave one out cv will be implemented.";

    opt3 = G_define_option();
    opt3->key = "seed";
    opt3->type = TYPE_INTEGER;
    opt3->required = YES;
    opt3->description =
	"Seed for the initialization (>=0), which specifies a starting point\n\t\tfor the random number sequence. Replicate same experiment.";
    opt3->answer = "0";

    flag_c = G_define_flag();
    flag_c->key = 'c';
    flag_c->description = "selected method: cross-validation.";

    flag_b = G_define_flag();
    flag_b->key = 'b';
    flag_b->description = "selected method: bootstrap.";


    if (G_parser(argc, argv))
	exit(1);


    /*read parameters */
    sscanf(opt2->answer, "%d", &n_sets);
    if (n_sets <= 0) {
	sprintf(tmpbuf, "n_sets must be >0");
	G_fatal_error(tmpbuf);
    }

    sscanf(opt3->answer, "%d", &seed);
    if (seed < 0) {
	sprintf(tmpbuf, "seed must be >=0");
	G_fatal_error(tmpbuf);
    }

    /*read features */
    read_features(opt1->answer, &features, -1);



    if (flag_b->answer) {
	sprintf(filelab, "%s__bootstrap__labels", opt1->answer);
	flab = fopen(filelab, "w");

	tr_features = (Features *) G_calloc(n_sets, sizeof(Features));
	ts_features = (Features *) G_calloc(n_sets, sizeof(Features));

	prob = (double *)G_calloc(features.nexamples, sizeof(double));
	for (i = 0; i < features.nexamples; i++)
	    prob[i] = 1. / features.nexamples;
	random_labels = (int *)G_calloc(features.nexamples, sizeof(int));
	non_extracted = (int *)G_calloc(features.nexamples, sizeof(int));


	for (i = 0; i < n_sets; i++) {
	    idum = i + seed;
	    Bootsamples_rseed(features.nexamples, prob, random_labels, &idum);

	    /*training */
	    tr_features[i].file = features.file;
	    tr_features[i].nexamples = features.nexamples;
	    tr_features[i].examples_dim = features.examples_dim;
	    tr_features[i].value =
		(double **)G_calloc(tr_features[i].nexamples,
				    sizeof(double *));
	    tr_features[i].class =
		(int *)G_calloc(tr_features[i].nexamples, sizeof(int));
	    for (j = 0; j < tr_features[i].nexamples; j++) {
		tr_features[i].value[j] = features.value[random_labels[j]];
		tr_features[i].class[j] = features.class[random_labels[j]];
	    }
	    tr_features[i].p_classes = features.p_classes;
	    tr_features[i].nclasses = features.nclasses;
	    tr_features[i].mean = features.mean;
	    tr_features[i].sd = features.sd;
	    tr_features[i].f_normalize = features.f_normalize;
	    tr_features[i].f_standardize = features.f_standardize;
	    tr_features[i].f_mean = features.f_mean;
	    tr_features[i].f_variance = features.f_variance;
	    tr_features[i].f_pca = features.f_pca;
	    tr_features[i].pca_class = features.pca_class;
	    tr_features[i].pca = features.pca;
	    tr_features[i].training = features.training;
	    tr_features[i].npc = features.npc;
	    tr_features[i].training.file = "generated by i.pr_subsets";

	    sprintf(fileout, "%s__tr_bootstrap__%d", opt1->answer, i + 1);
	    write_features(fileout, &tr_features[i]);

	    fprintf(flab, "Training %d:\n", i + 1);

	    for (j = 0; j < (tr_features[i].nexamples - 1); j++) {
		fprintf(flab, "%d\t", random_labels[j] + 1);
	    }
	    fprintf(flab, "%d\n",
		    random_labels[tr_features[i].nexamples - 1] + 1);

	    /*test */
	    n_non_extracted = 0;
	    for (k = 0; k < tr_features[i].nexamples; k++) {
		extracted = 0;
		for (j = 0; j < tr_features[i].nexamples; j++) {
		    if (k == random_labels[j]) {
			extracted = 1;
			break;
		    }
		}
		if (!extracted) {
		    non_extracted[n_non_extracted] = k;
		    n_non_extracted++;
		}
	    }

	    ts_features[i].file = features.file;
	    ts_features[i].nexamples = n_non_extracted;
	    ts_features[i].examples_dim = features.examples_dim;
	    ts_features[i].value = (double **)G_calloc(n_non_extracted,
						       sizeof(double *));
	    ts_features[i].class = (int *)G_calloc(n_non_extracted,
						   sizeof(int));
	    for (j = 0; j < n_non_extracted; j++) {
		ts_features[i].value[j] = features.value[non_extracted[j]];
		ts_features[i].class[j] = features.class[non_extracted[j]];
	    }
	    ts_features[i].p_classes = features.p_classes;
	    ts_features[i].nclasses = features.nclasses;
	    ts_features[i].mean = features.mean;
	    ts_features[i].sd = features.sd;
	    ts_features[i].f_normalize = features.f_normalize;
	    ts_features[i].f_standardize = features.f_standardize;
	    ts_features[i].f_mean = features.f_mean;
	    ts_features[i].f_variance = features.f_variance;
	    ts_features[i].f_pca = features.f_pca;
	    ts_features[i].pca_class = features.pca_class;
	    ts_features[i].pca = features.pca;
	    ts_features[i].training = features.training;
	    ts_features[i].npc = features.npc;
	    ts_features[i].training.file = "generated by i.pr_subsets";

	    sprintf(fileout, "%s__ts_bootstrap__%d", opt1->answer, i + 1);
	    write_features(fileout, &ts_features[i]);

	    fprintf(flab, "Test %d:\n", i + 1);

	    for (j = 0; j < (ts_features[i].nexamples - 1); j++) {
		fprintf(flab, "%d\t", non_extracted[j] + 1);
	    }
	    fprintf(flab, "%d\n",
		    non_extracted[ts_features[i].nexamples - 1] + 1);

	}
	G_free(prob);
	G_free(random_labels);
	G_free(non_extracted);

	return 0;
    }


    if (flag_c->answer) {
	if (n_sets == 1) {
	    tr_features =
		(Features *) G_calloc(features.nexamples, sizeof(Features));
	    ts_features =
		(Features *) G_calloc(features.nexamples, sizeof(Features));

	    /*training */
	    for (i = 0; i < features.nexamples; i++) {
		tr_features[i].file = features.file;
		tr_features[i].nexamples = features.nexamples - 1;
		tr_features[i].examples_dim = features.examples_dim;
		tr_features[i].value =
		    (double **)G_calloc(features.nexamples - 1,
					sizeof(double *));
		tr_features[i].class =
		    (int *)G_calloc(features.nexamples - 1, sizeof(int));
		indx = 0;
		for (j = 0; j < features.nexamples; j++) {
		    if (j != i) {
			tr_features[i].value[indx] = features.value[j];
			tr_features[i].class[indx++] = features.class[j];
		    }
		}

		tr_features[i].p_classes = features.p_classes;
		tr_features[i].nclasses = features.nclasses;
		tr_features[i].mean = features.mean;
		tr_features[i].sd = features.sd;
		tr_features[i].f_normalize = features.f_normalize;
		tr_features[i].f_standardize = features.f_standardize;
		tr_features[i].f_mean = features.f_mean;
		tr_features[i].f_variance = features.f_variance;
		tr_features[i].f_pca = features.f_pca;
		tr_features[i].pca_class = features.pca_class;
		tr_features[i].pca = features.pca;
		tr_features[i].training = features.training;
		tr_features[i].npc = features.npc;
		tr_features[i].training.file = "generated by i.pr_subsets";

		sprintf(fileout, "%s__tr_l1ocv__%d", opt1->answer, i + 1);
		write_features(fileout, &tr_features[i]);

		/*test */
		ts_features[i].file = features.file;
		ts_features[i].nexamples = 1;
		ts_features[i].examples_dim = features.examples_dim;
		ts_features[i].value =
		    (double **)G_calloc(1, sizeof(double *));
		ts_features[i].class = (int *)G_calloc(1, sizeof(int));
		ts_features[i].value[0] = features.value[i];
		ts_features[i].class[0] = features.class[i];


		ts_features[i].p_classes = features.p_classes;
		ts_features[i].nclasses = features.nclasses;
		ts_features[i].mean = features.mean;
		ts_features[i].sd = features.sd;
		ts_features[i].f_normalize = features.f_normalize;
		ts_features[i].f_standardize = features.f_standardize;
		ts_features[i].f_mean = features.f_mean;
		ts_features[i].f_variance = features.f_variance;
		ts_features[i].f_pca = features.f_pca;
		ts_features[i].pca_class = features.pca_class;
		ts_features[i].pca = features.pca;
		ts_features[i].training = features.training;
		ts_features[i].npc = features.npc;
		ts_features[i].training.file = "generated by i.pr_subsets";

		sprintf(fileout, "%s__ts_l1ocv__%d", opt1->answer, i + 1);
		write_features(fileout, &ts_features[i]);
	    }
	    return 0;
	}
	else {
	    sprintf(filelab, "%s__cv__labels", opt1->answer);
	    flab = fopen(filelab, "w");

	    tr_features = (Features *) G_calloc(n_sets, sizeof(Features));
	    ts_features = (Features *) G_calloc(n_sets, sizeof(Features));

	    if (n_sets > features.nexamples) {
		sprintf(tmpbuf,
			"n_sets must be <= %d (=number of training data) if you want to use cross-validation",
			features.nexamples);
		G_fatal_error(tmpbuf);
	    }

	    probok =
		pow(1. - pow(1. - 1. / n_sets, (double)features.nexamples),
		    (double)n_sets);
	    if (probok < 0.95) {
		sprintf(tmpbuf,
			"the probability of extracting %d non empty test sets is less than 0.95 (the probability is exactly %e). Sorry but I don't like to take this risk.",
			n_sets, probok);
		G_fatal_error(tmpbuf);
	    }

	    random_labels = (int *)G_calloc(features.nexamples, sizeof(int));
	    for (i = 0; i < n_sets; i++) {
		idum = i + seed;
		for (j = 0; j < features.nexamples; j++)
		    random_labels[j] = (int)(n_sets * ran1(&idum));

		/*training */
		n_extracted = 0;
		for (j = 0; j < features.nexamples; j++)
		    if (random_labels[j] != i)
			n_extracted++;

		tr_features[i].file = features.file;
		tr_features[i].nexamples = n_extracted;
		tr_features[i].examples_dim = features.examples_dim;
		tr_features[i].value = (double **)G_calloc(n_extracted,
							   sizeof(double *));
		tr_features[i].class = (int *)G_calloc(n_extracted,
						       sizeof(int));

		fprintf(flab, "Training %d:\n", i + 1);

		indx = 0;

		for (j = 0; j < (features.nexamples - 1); j++) {
		    if (random_labels[j] != i) {
			tr_features[i].value[indx] = features.value[j];
			tr_features[i].class[indx++] = features.class[j];
			fprintf(flab, "%d\t", j + 1);
		    }
		}

		if (random_labels[features.nexamples - 1] != i) {
		    tr_features[i].value[indx] =
			features.value[features.nexamples - 1];
		    tr_features[i].class[indx++] =
			features.class[features.nexamples - 1];
		    fprintf(flab, "%d", features.nexamples);
		}

		fprintf(flab, "\n");

		tr_features[i].p_classes = features.p_classes;
		tr_features[i].nclasses = features.nclasses;
		tr_features[i].mean = features.mean;
		tr_features[i].sd = features.sd;
		tr_features[i].f_normalize = features.f_normalize;
		tr_features[i].f_standardize = features.f_standardize;
		tr_features[i].f_mean = features.f_mean;
		tr_features[i].f_variance = features.f_variance;
		tr_features[i].f_pca = features.f_pca;
		tr_features[i].pca_class = features.pca_class;
		tr_features[i].pca = features.pca;
		tr_features[i].training = features.training;
		tr_features[i].npc = features.npc;
		tr_features[i].training.file = "generated by i.pr_subsets";

		sprintf(fileout, "%s__tr_%dcv__%d", opt1->answer, n_sets,
			i + 1);
		write_features(fileout, &tr_features[i]);


		/*test */
		n_non_extracted = 0;
		for (j = 0; j < features.nexamples; j++)
		    if (random_labels[j] == i)
			n_non_extracted++;

		tr_features[i].file = features.file;
		tr_features[i].nexamples = n_non_extracted;
		tr_features[i].examples_dim = features.examples_dim;
		tr_features[i].value = (double **)G_calloc(n_non_extracted,
							   sizeof(double *));
		tr_features[i].class = (int *)G_calloc(n_non_extracted,
						       sizeof(int));


		fprintf(flab, "Test %d:\n", i + 1);

		indx = 0;
		for (j = 0; j < (features.nexamples - 1); j++) {
		    if (random_labels[j] == i) {
			tr_features[i].value[indx] = features.value[j];
			tr_features[i].class[indx++] = features.class[j];
			fprintf(flab, "%d\t", j + 1);
		    }
		}

		if (random_labels[features.nexamples - 1] == i) {
		    tr_features[i].value[indx] =
			features.value[features.nexamples - 1];
		    tr_features[i].class[indx++] =
			features.class[features.nexamples - 1];
		    fprintf(flab, "%d", features.nexamples);
		}

		fprintf(flab, "\n");

		tr_features[i].p_classes = features.p_classes;
		tr_features[i].nclasses = features.nclasses;
		tr_features[i].mean = features.mean;
		tr_features[i].sd = features.sd;
		tr_features[i].f_normalize = features.f_normalize;
		tr_features[i].f_standardize = features.f_standardize;
		tr_features[i].f_mean = features.f_mean;
		tr_features[i].f_variance = features.f_variance;
		tr_features[i].f_pca = features.f_pca;
		tr_features[i].pca_class = features.pca_class;
		tr_features[i].pca = features.pca;
		tr_features[i].training = features.training;
		tr_features[i].npc = features.npc;
		tr_features[i].training.file = "generated by i.pr_subsets";

		sprintf(fileout, "%s__ts_%dcv__%d", opt1->answer, n_sets,
			i + 1);
		write_features(fileout, &tr_features[i]);

	    }
	    G_free(random_labels);
	    return 0;
	}
    }

    return 0;
}
